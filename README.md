# Sorting networks

Playground for exploring implementation techniques for sorting networks.  These can sort small arrays much faster
than `Array.Sort()`; depending on the size (4-32) and pattern, the speedup is 3-12X. See [benchmarks](#benchmarks) below.
The generated assembly in Release mode is lean and mean, and seems comparable with what would have been generated by
a C++ compiler.

## Changes since v1

- Implemented Fisher-Yates shuffle; it is now used in benchmarks for more reliable validation of sorters.
- Support for arbitrary length arrays, i.e., not just lengths that are power of 2.
- Exhaustive validation now checks sorters for all lengths 4-32.
- Added (32-bit) float sorter.

# Project structure

The projects are developed with Visual Studio 2019 and target netcore3.1.  The solution consists of two projects.

## SNBenchmark

This project dependes on BenchmarkDotNet. It contains validation code, benchmarks and demonstrates the use of sorting methods.
The main program must be run with a single argument: `VI`, `VF` or `B`. 

When run with `VI`, it runs an exhaustive validation of integer networks for element counts of up to 32.  When run with `VF`
it runs an exhaustive validation of float networks for element counts of up to 32.  Larger sizes are infeasible, as `2^N`
zero/one inputs would have to be tested.

When run with "B", it passes the rest of the arguments to BenchmarkDotNet.  Without any additional arguments, it will present a menu.
All benchmarks call `Environment.FailFast` if the result is found to be unsorted so that this can be detected in the logs.

## SortingNetworks

`SortingNetworks` project is the main code and has no dependencies.  The high-performance public types use `unsafe`
code and can only be used from `unsafe` methods.  The code depends on AVX2 instruction set.  In addition, `AESRand`
class depends on AES-NI instruction set.  

### Sorting

The main interface is `UnsafeSort<T>` class which exposes a static factory function.  The actual sorting code is in
`IntSorter` and `FloatSorter` classes.  You are not expected to understand how it works without studying [references](#references).
The code to handle lengths that are not power of two introduces some overhead even for small arrays, so `PeriodicInt` class is
provided with methods for sorting arrays of lengths 4, 8, 16 and 32; see [benchmarks](#benchmarks) below.

`UnsafeSort<T>` and `PeriodicInt` classes have no mutable internal state, so it is recommended to use a single (non-static) instance
throughout the program (see remark about statics below).

Directory `Attic` contains the (failed) experiment with expression trees and earlier (less performant) iterations of the
periodic network.

### Random numbers

This subsystem consists of three classes: and abstract `UnsafeRandom` class and two concrete classes: `AESRand` and `MWC1616Rand`.
These can be instantiated directly.  **NB!** The correctness of the code and the quality of random numbers has not been verified!
Benchmarks use `MWC1616Rand` with a fixed seed as `AESRand` seemed to generate some obvious patterns.

# Lessons learned
These were learned by inspecting the generated assembly code in Release mode.

Accessing static data has more overhead than accessing instance data: extraneous CALL instructions into the runtime
are generated.  My guess is that these ensure thread-safe, once-only static initialization semantics.

Accessing `ref` parameters as in `Periodics16Branchless` generates a lot of load/store instructions.
It is much more efficient to load ref parameters into locals at the beginning of the procedure and store
results at the end, as in `PeriodicInt`.

`Periodic16Expr` demonstrates how to build a sorter with expression trees.  The generated assembly is OK,
save for the long prologue/epilogue sequences  This makes the overhead of calling a lambda compiled at run-time
way too big for this application.

`unsafe` is not viral: Method `A` is allowed to call `unsafe` method `B` without `A` having to be marked
unsafe as well.  Also, it is allowed to assign an `unsafe` method to a non-unsafe delegate variable.

`System.Random` does not have consistent timing: when used in the baseline benchmark, the results almost always
contained a warning about it having a bimodal distribution.  This makes it rather unusable in baseline benchmarks.
Therefore `UnsafeRandom`, `AESRand` and `MWC1616Rand` classes were implemented.  Of these, only MWC is being used.

Generics suck for numeric code.  I couldn't figure out how to write a generic `bool IsSorted(T[])` method that'd
work for any numeric type.  Adding `where T : unmanaged` doesn't help as the compiler doesn't know that unmanaged
types are comparable with less-than and equal.  Nor does it seem possible to write `void Iota(T[] data)` that'd
fill `data` with numbers from `0 .. Length-1`.

I attempted to make concrete benchmark classes `sealed`, but that makes BenchmarkDotNet fail because it apparently
needs to derive from the benchmark class.

RyuJIT has some impressive optimizations: despite branches in "block" methods in `PeriodicInt`, it manages to generate
branchless code when constants that branches depend on are known at compile-time.  It also elides unnecessary loads and
stores to/from ref variables and inlines impressively.  The generated machine code, however, is huge: 32-sorter is > 1kB
in size.  If considering larger sorters, inlining should be forced.

# Benchmarks

Raw benchmark data with excel file used to generate the report are in [BenchmarkResults](BenchmarkResults).  Main results
 are presented [here (PDF)](BenchmarkResults/Analysis.pdf) and are commented on in the next sections.  (Section titles correspond
 to page headers / XLS sheet names.)

I couldn't figure out how to coerce BenchmarkDotNet into treating the baseline as additive overhead instead of, well, _baseline_.
(Actually, that's what `[IterationSetup]` and `[IterationCleanup]` are for, but they come with a warning that they could spoil results
of microbenchmarks.)  The analysis presents results after subtracting the additive overhead.

## General observations

Even for small sizes, `UnsafeSort<int>` is slightly slower than PeriodicInt.  For example, `PeriodicInt` takes ~22ns to sort 16
elements, whereas `UnsafeSort<int>` takes ~38ns.  Even though the additional logic to handle all sizes between 9 and 16 is relatively
simple, it shows in running times.

## Configuration

The first page presents the hardware/software configuration under which the benchmarks were run.  Benchmarks were run on
low load, but not on a dedicated machine.  If anything, this only worsens the results.

## IntBenchmark

An observable anomaly is the extreme speedup at which the network sorts 8-element vectors; the same anomaly is not observable
for `Array.Sort`.  I have no explanation for this phenomenon.  For arrays of up to 1M elements, sorting network is 3-6 times
(ignoring the outliers for N=8,12) faster than `Array.Sort`.

## FloatBenchmark

Similar to integers, floating-point numbers are sorted 6-8 time faster than with `Array.Sort`.  The speedup curve has more
pronounced local minima and maxima.  The anomaly of extreme speedup is also observable and occurs for N=8,12,16.  For arrays
of up to 1M elements, sorting network is (ignoring the outliers) 3-6 times faster.

## Int vs Float

This chart compares relative performance of sorting integers vs floats, both for arrays (blue curve) and sorting networks
(orange curve).  In both cases, sorting integers is somewhat faster than sorting floats, though the difference is much more
pronounced for network sort.  As the array size grows, the difference in performance diminishes, i.e., the ratio converges
to 1, for both `Array.Sort` and network sort.

## Specialized (PeriodicInt)

This benchmark compares difference in performance when presented with different patterns: sorted in ascending order ("Asc",
i.e., already sorted), sorted in descending order ("Desc") and randomly ordered ("Rand").  It is observable that ascending
order is most favorable both for `Array.Sort` and network sort.  Descending order is more favorable for network sort.

That network sort performs better for ascending or descending sequences is an *unexplained anomaly*: the algorithm is
data-oblivious and always runs the same number of operations for a vector of given size, so it should run in the same
time regardless of any patterns in the input.  In other words, there seems to exist a side-channel that leaks information
about the input sequence.

## Algorithmic complexity considerations

`Array.Sort` uses [introsort](https://en.wikipedia.org/wiki/Introsort), which was determined by inspecting the source code
on GitHub.  Introsort has theoretical worst-case and average-case  performance of `O(n lg n)`.  The periodic sorting network
has theoretical performance of `O(n lg^2 n)`, irrespective of input (though see the comment about anomalies in the previous section).

"Runtime fit" diagrams for IntBenchmark and FloatBenchmark display regression curves giving the highest R-number, with their
equations summarized in the following table

| Type  | Array.Sort                        | Network sort                       |
|-------|-----------------------------------|------------------------------------|
| Int   | y = 11.565*N^1.525 (R2 = 0.9994)  | y = 1.5987*N^1.2132 (R2 = 0.9987)  |
| Float | y = 14.604*N^1.1394 (R2 = 0.9956) | y = 1.9795*N^1.876 (R2 = 0.998)    |

Trying to fit the data to their theoretical curves ("LogFit" sheet), we achieve slightly higher R-squared numbers (presented
for integers only):

| Algorithm  | Fit                                                 |
|------------|-----------------------------------------------------|
| Array.Sort | y = 3.9669*N*lg(N) - 5227.5*lg(N) (R2 = 0.9998)     |
| Network    | y = 0.0647*N*lg^2(N) - 14.203*lg^2(N) (R2 = 0.9992) |


## Invocation: direct vs delegate vs compiled expression

This project was initially started to investigate manual code generation using expression trees, but it turns out that
these are unsuitable for high-performance scenarios as the prologue/epilogue in the generated code has way too high overhead
(see `ExpressionInvocationBenchmark`):

|           Method |      Mean |    Error |   StdDev |
|----------------- |----------:|---------:|---------:|
|     DirectInvoke |  45.51 ns | 0.934 ns | 2.147 ns |
| ExpressionInvoke | 124.08 ns | 2.512 ns | 6.747 ns |

On the other hand, there is no substantial difference between directly invoking an instance method, or invoking it through an
abstract base method.  Thus there is no penalty in using the more convenient `UnsafeSort` class as opposed to directly calling
methods on an instance of `PeriodicInt`:


|         Method |     Mean |    Error |   StdDev |
|--------------- |---------:|---------:|---------:|
| AbstractInvoke | 23.80 ns | 0.421 ns | 0.603 ns |
| ConcreteInvoke | 23.28 ns | 0.310 ns | 0.290 ns |

NB! The results between the two benchmarks are not directly comparable as they run different algorithms.

# References

D. E. Knuth, The Art of Computer Programming, vol. 3, section 5.3.4 for basic exposition. The ""periodic" network as
implemented here appears in TAOCP exercise 53, but has first been described by Dowd et al.: "The Periodic Balanced Sorting
Network", JACM Vol. 36, No. 4, October 1989, pp. 738-757.

Other references appear in code comments.
